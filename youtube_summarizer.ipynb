{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAuthenticationError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m openai\u001B[38;5;241m.\u001B[39morganization \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_ORG\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m      4\u001B[0m openai\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOPENAI_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m openai\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenAI API key not found. Please set the OPENAI_KEY environment variable.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/devConda/lib/python3.8/site-packages/openai/api_resources/abstract/listable_api_resource.py:52\u001B[0m, in \u001B[0;36mListableAPIResource.list\u001B[0;34m(cls, api_key, request_id, api_version, organization, api_base, api_type, **params)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlist\u001B[39m(\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m     51\u001B[0m ):\n\u001B[0;32m---> 52\u001B[0m     requestor, url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__prepare_list_requestor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43morganization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m requestor\u001B[38;5;241m.\u001B[39mrequest(\n\u001B[1;32m     61\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url, params, request_id\u001B[38;5;241m=\u001B[39mrequest_id\n\u001B[1;32m     62\u001B[0m     )\n\u001B[1;32m     63\u001B[0m     openai_object \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mconvert_to_openai_object(\n\u001B[1;32m     64\u001B[0m         response, api_key, api_version, organization\n\u001B[1;32m     65\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/devConda/lib/python3.8/site-packages/openai/api_resources/abstract/listable_api_resource.py:20\u001B[0m, in \u001B[0;36mListableAPIResource.__prepare_list_requestor\u001B[0;34m(cls, api_key, api_version, organization, api_base, api_type)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__prepare_list_requestor\u001B[39m(\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m     api_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     19\u001B[0m ):\n\u001B[0;32m---> 20\u001B[0m     requestor \u001B[38;5;241m=\u001B[39m \u001B[43mapi_requestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAPIRequestor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_key\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_base\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapi_base\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43mapi_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mapi_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morganization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m     typed_api_type, api_version \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_get_api_type_and_version(\n\u001B[1;32m     29\u001B[0m         api_type, api_version\n\u001B[1;32m     30\u001B[0m     )\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m typed_api_type \u001B[38;5;129;01min\u001B[39;00m (ApiType\u001B[38;5;241m.\u001B[39mAZURE, ApiType\u001B[38;5;241m.\u001B[39mAZURE_AD):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/devConda/lib/python3.8/site-packages/openai/api_requestor.py:130\u001B[0m, in \u001B[0;36mAPIRequestor.__init__\u001B[0;34m(self, key, api_base, api_type, api_version, organization)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    123\u001B[0m     key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    127\u001B[0m     organization\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    128\u001B[0m ):\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_base \u001B[38;5;241m=\u001B[39m api_base \u001B[38;5;129;01mor\u001B[39;00m openai\u001B[38;5;241m.\u001B[39mapi_base\n\u001B[0;32m--> 130\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m key \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdefault_api_key\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_type \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    132\u001B[0m         ApiType\u001B[38;5;241m.\u001B[39mfrom_str(api_type)\n\u001B[1;32m    133\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m api_type\n\u001B[1;32m    134\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m ApiType\u001B[38;5;241m.\u001B[39mfrom_str(openai\u001B[38;5;241m.\u001B[39mapi_type)\n\u001B[1;32m    135\u001B[0m     )\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_version \u001B[38;5;241m=\u001B[39m api_version \u001B[38;5;129;01mor\u001B[39;00m openai\u001B[38;5;241m.\u001B[39mapi_version\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/devConda/lib/python3.8/site-packages/openai/util.py:186\u001B[0m, in \u001B[0;36mdefault_api_key\u001B[0;34m()\u001B[0m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m openai\u001B[38;5;241m.\u001B[39mapi_key\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m openai\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mAuthenticationError(\n\u001B[1;32m    187\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo API key provided. You can set your API key in code using \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopenai.api_key = <API-KEY>\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mopenai.api_key_path = <PATH>\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    188\u001B[0m     )\n",
      "\u001B[0;31mAuthenticationError\u001B[0m: No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://onboard.openai.com for details, or email support@openai.com if you have any questions."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "openai.organization = os.environ.get(\"OPENAI_ORG\", None)\n",
    "openai.api_key = os.environ.get(\"OPENAI_KEY\", None)\n",
    "\n",
    "\n",
    "if openai.api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_KEY environment variable.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:15:23.421233Z",
     "end_time": "2023-04-08T12:15:23.425894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "class YoutubeScraper:\n",
    "    \"\"\"\n",
    "    A class to scrape YouTube video metadata.\n",
    "    This gets the video title, description, chapters, and transcript.\n",
    "\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    url : str\n",
    "        The YouTube video URL\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.video_key = self.extract_video_key(url)\n",
    "        self.data = None\n",
    "\n",
    "    def get_video_info(self):\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0'\n",
    "        }\n",
    "\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            script = soup.find('script', string=lambda x: x and 'var ytInitialPlayerResponse' in x)\n",
    "            if not script:\n",
    "                raise ValueError('Failed to find ytInitialPlayerResponse in the page source.')\n",
    "\n",
    "            json_str = re.search(r'var ytInitialPlayerResponse = ({.*?});', script.string).group(1)\n",
    "            data = json.loads(json_str)\n",
    "            video_details = data.get('videoDetails', {})\n",
    "\n",
    "            title = video_details.get('title')\n",
    "            description = video_details.get('shortDescription')\n",
    "\n",
    "            script = soup.find('script', string=lambda x: x and 'var ytInitialData' in x)\n",
    "            if not script:\n",
    "                raise ValueError('Failed to find ytInitialData in the page source.')\n",
    "\n",
    "            json_str = re.search(r'var ytInitialData = ({.*?});', script.string).group(1)\n",
    "            yt_initial_data = json.loads(json_str)\n",
    "\n",
    "            chapters = {}\n",
    "            engagement_panels = yt_initial_data.get('engagementPanels', [])\n",
    "            for panel in engagement_panels:\n",
    "                contents = panel.get('engagementPanelSectionListRenderer', {}).get('content', {}).get(\n",
    "                    'macroMarkersListRenderer', {}).get('contents', [])\n",
    "                for content in contents:\n",
    "                    timestamp = content.get('macroMarkersListItemRenderer', {}).get('timeDescription', {}).get(\n",
    "                        'simpleText')\n",
    "                    chapter_title = content.get('macroMarkersListItemRenderer', {}).get('title', {}).get('simpleText')\n",
    "                    if timestamp is not None and chapter_title is not None:\n",
    "                        chapters[timestamp] = chapter_title\n",
    "\n",
    "            self.data = {\n",
    "                'title': title,\n",
    "                'description': description,\n",
    "                'chapters': chapters,\n",
    "                'transcripts': YouTubeTranscriptApi.get_transcript(self.video_key)\n",
    "            }\n",
    "            return self\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.url)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_video_key(url):\n",
    "        parsed_url = urllib.parse.urlparse(url)\n",
    "        query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "        video_key = query_params.get('v', [None])[0]\n",
    "        return video_key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:10:41.190905Z",
     "end_time": "2023-04-08T12:10:41.199085Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "class YouTubeInfo:\n",
    "    def __init__(self, video_url, ignore_chapters=False):\n",
    "        self.transcripts = None\n",
    "        self.title = None\n",
    "        self.description = None\n",
    "        self.chapters = None\n",
    "        self.segments = None\n",
    "        self.video_url = video_url\n",
    "        self.ignore_chapters = ignore_chapters\n",
    "\n",
    "    @staticmethod\n",
    "    def seconds_to_timestamp(seconds):\n",
    "        seconds = round(float(seconds))\n",
    "        h, remainder = divmod(seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def time_to_seconds(time_str):\n",
    "        time_parts = list(map(int, time_str.split(':')))\n",
    "        if len(time_parts) == 3:\n",
    "            h, m, s = time_parts\n",
    "        elif len(time_parts) == 2:\n",
    "            h = 0\n",
    "            m, s = time_parts\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid time format: {time_str}\")\n",
    "        return h * 3600 + m * 60 + s\n",
    "\n",
    "\n",
    "    def get_video_info(self):\n",
    "        from YoutubeScraper import YoutubeScraper\n",
    "        data = YoutubeScraper(self.video_url).get_video_info().get_data()\n",
    "        self.transcripts = data['transcripts']\n",
    "        self.title = data['title']\n",
    "        self.description = data['description']\n",
    "        if bool(data['chapters']) and not self.ignore_chapters:\n",
    "            self.chapters = data['chapters']\n",
    "        else:\n",
    "            self.chapters = None\n",
    "        return self\n",
    "\n",
    "    def group_transcripts_by_chapters(self):\n",
    "        chapters = sorted([(self.time_to_seconds(k), v) for k, v in self.chapters.items()])\n",
    "        grouped_transcripts = [{\"title\": c, \"time\": k, \"segments\": []} for k, c in chapters]\n",
    "\n",
    "        for segment in self.transcripts:\n",
    "            start_time = segment['start']\n",
    "\n",
    "            for i, chapter in enumerate(grouped_transcripts):\n",
    "                chapter_start = chapter[\"time\"]\n",
    "                if i + 1 < len(grouped_transcripts) and chapter_start <= start_time < grouped_transcripts[i + 1][\"time\"]:\n",
    "                    chapter[\"segments\"].append(segment)\n",
    "                    break\n",
    "                elif i + 1 == len(grouped_transcripts) and start_time >= chapter_start:\n",
    "                    chapter[\"segments\"].append(segment)\n",
    "                    break\n",
    "\n",
    "        return grouped_transcripts\n",
    "\n",
    "\n",
    "    def json(self):\n",
    "        return {\n",
    "            'title': self.title,\n",
    "            'description': self.description,\n",
    "            'chapters': self.chapters,\n",
    "            'transcripts': self.transcripts\n",
    "        }\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self.json())\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.title)\n",
    "\n",
    "    def __dict__(self):\n",
    "        return self.json()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.transcripts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:10:42.018832Z",
     "end_time": "2023-04-08T12:10:42.023820Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class TranscriptSummarizer:\n",
    "    \"\"\"\n",
    "    Takes in transcripts and summarizes them with the OpenAi API.\n",
    "    :param video_url: The url of the video to summarize\n",
    "    :param ignore_chapters: If True, the chapters will be ignored and video will be summarized as a whole.\n",
    "    \"\"\"\n",
    "    def __init__(self, video_url, ignore_chapters=False, debug=False):\n",
    "        self.yt_info = YouTubeInfo(video_url, ignore_chapters).get_video_info()\n",
    "        self.encoding = tiktoken.get_encoding(\"p50k_base\")\n",
    "        self.processed_chapters = self.process_chapters()\n",
    "        self.DEFAULT_PROMPT = '\\nWrite a summary of this transcript using markdown formatting. Try to categorize when it will help. \\n\\n## {}\\n'\n",
    "        self.CONT_PROMPT = 'Continue writing your summary of this transcript. Try to categorize when it will help. This is where you left off:\\n{}'\n",
    "        self.MAX_TOKENS = 4080\n",
    "        self.RESPONSE_TOKENS = 500\n",
    "        self.PROMPT_TOKENS = len(self.encoding.encode(self.DEFAULT_PROMPT))\n",
    "        self.BUFFER_TOKENS = 100\n",
    "        self.MAX_CONTENT_TOKENS = self.MAX_TOKENS - self.PROMPT_TOKENS - self.BUFFER_TOKENS - self.RESPONSE_TOKENS\n",
    "        self.AI_MODEL = 'text-davinci-003'\n",
    "        self.DEBUG = debug\n",
    "        self.summary = None\n",
    "\n",
    "    def process_chapters(self):\n",
    "        if self.yt_info.chapters:\n",
    "            processed_chapters = self.yt_info.group_transcripts_by_chapters()\n",
    "        else:\n",
    "            processed_chapters = [{\"title\": \"Full Summary\", \"time\": 0, \"segments\": self.yt_info.transcripts}]\n",
    "        return processed_chapters\n",
    "\n",
    "    def calculate_content_segments(self, content):\n",
    "        from math import ceil\n",
    "        content_tokens = len(self.encoding.encode(content))\n",
    "        return ceil(content_tokens / self.MAX_CONTENT_TOKENS), content_tokens\n",
    "\n",
    "    def format_content_segments(self, segments):\n",
    "        return ''.join([f'[{YouTubeInfo.seconds_to_timestamp(s[\"start\"])}]{s[\"text\"]}' for s in segments])\n",
    "\n",
    "    def split_array(self, array, n_chunks):\n",
    "        chunk_size = len(array) // n_chunks\n",
    "        remainder = len(array) % n_chunks\n",
    "        result = []\n",
    "        index = 0\n",
    "\n",
    "        for i in range(n_chunks):\n",
    "            size = chunk_size + (1 if i < remainder else 0)\n",
    "            result.append(array[index:index + size])\n",
    "            index += size\n",
    "\n",
    "        return result\n",
    "\n",
    "    def call_openai_api(self, prompt, temperature):\n",
    "        return openai.Completion.create(\n",
    "            model=self.AI_MODEL,\n",
    "            prompt=prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=self.RESPONSE_TOKENS,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "\n",
    "    def split_summary(self, summary, max_length):\n",
    "        summary_parts = []\n",
    "        while len(summary) > max_length:\n",
    "            split_point = summary[:max_length].rfind('\\n')\n",
    "            summary_parts.append(summary[:split_point])\n",
    "            summary = summary[split_point:]\n",
    "        summary_parts.append(summary)\n",
    "        return summary_parts\n",
    "\n",
    "    def summarize(self):\n",
    "        for chapter in self.processed_chapters:\n",
    "            initial_process = self.format_content_segments(chapter['segments'])\n",
    "            segments, initial_tokens = self.calculate_content_segments(initial_process)\n",
    "            if self.DEBUG:\n",
    "                print(f'{chapter[\"title\"]} | {initial_tokens = } | {segments = }')\n",
    "            if segments == 1:\n",
    "                chapter['processed_segments'] = [initial_process]\n",
    "            else:\n",
    "                secondary_segments = self.split_array(chapter['segments'], segments)\n",
    "                chapter['processed_segments'] = [self.format_content_segments(s) for s in secondary_segments]\n",
    "\n",
    "            chapter_title = chapter['title']\n",
    "            chapter_segments = chapter['processed_segments']\n",
    "            chapter['summary'] = ''\n",
    "            chapter['responses'] = []\n",
    "            for i, segment in enumerate(chapter_segments):\n",
    "                if i == 0:\n",
    "                    full_segment = segment + self.DEFAULT_PROMPT.format(chapter_title)\n",
    "                else:\n",
    "                    full_segment = segment + self.CONT_PROMPT.format(chapter['summary'][-3 * self.BUFFER_TOKENS])\n",
    "                # ChatGPT Note: Create a wrapper for calling the OpenAI API\n",
    "                response = self.call_openai_api(\n",
    "                    prompt=full_segment,\n",
    "                    temperature=0.3,\n",
    "                )\n",
    "                chapter['responses'].append(response)\n",
    "                chapter['summary'] += response.choices[0].text\n",
    "                reduction_percent = round(100.00 - response.usage.completion_tokens / response.usage.prompt_tokens * 100, 2)\n",
    "                if self.DEBUG:\n",
    "                    print(f'{chapter_title} | {i + 1}/{len(chapter_segments)} | {reduction_percent}%')\n",
    "\n",
    "        first_summary = f'# {self.yt_info.title}\\n\\n## Chapters\\n'\n",
    "        for chapter in self.processed_chapters:\n",
    "            first_summary += f'### {chapter[\"title\"]}\\n'\n",
    "            first_summary += chapter['summary']\n",
    "            first_summary += '\\n\\n'\n",
    "\n",
    "        summary_parts = self.split_summary(first_summary, self.MAX_CONTENT_TOKENS)\n",
    "        self.summary = ''\n",
    "        for i, summary_part in enumerate(summary_parts):\n",
    "            if i == 0:\n",
    "                prompt = summary_part + '\\n Write an executive summary of this outline using markdown formatting.\\n\\n'\n",
    "            else:\n",
    "                prompt = summary_part + '\\n Continue writing your executive summary of this outline. This is where you left off:\\n\\n' + \\\n",
    "                self.summary[-3 * self.BUFFER_TOKENS:]\n",
    "\n",
    "            response = self.call_openai_api(\n",
    "                prompt=prompt,\n",
    "                temperature=0.5,\n",
    "            )\n",
    "            self.summary += response.choices[0].text\n",
    "\n",
    "        return self\n",
    "\n",
    "    def generate_markdown_output(self):\n",
    "        md_output = f'# {self.yt_info.title}\\n'\n",
    "        md_output += f'## Executive Summary\\n{self.summary}\\n\\n## Chapters\\n'\n",
    "        for chapter in self.processed_chapters:\n",
    "            md_output += f'### {chapter[\"title\"]}\\n'\n",
    "            md_output += chapter['summary']\n",
    "            md_output += '\\n\\n'\n",
    "        return md_output\n",
    "\n",
    "    def generate_html_output(self):\n",
    "        html_output = f'<h1>{self.yt_info.title}</h1>'\n",
    "        html_output += f'<h2>Executive Summary</h2><p>{self.summary}</p><h2>Chapters</h2>'\n",
    "        for chapter in self.processed_chapters:\n",
    "            html_output += f'<h3>{chapter[\"title\"]}</h3>'\n",
    "            html_output += chapter['summary']\n",
    "            html_output += '<hr />'\n",
    "        return html_output\n",
    "\n",
    "    def render_markdown(self):\n",
    "        from IPython.display import display, Markdown\n",
    "        return display(Markdown(self.generate_markdown_output()))\n",
    "\n",
    "    def render_html(self):\n",
    "        from IPython.display import display, HTML\n",
    "        return display(HTML(self.generate_html_output()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:45:09.841847Z",
     "end_time": "2023-04-08T13:45:09.844035Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/markdown": "# Why Are Animals Symmetrical?\n## Executive Summary\nBilaterians are a large group of animals that share the trait of bilateral symmetry. This trait is inherited from a common ancestor and is shared by more than 95% of all land animals. They have a body plan consisting of a tube with two openings and complex sensory organs that give them an advantage over non-bilaterians. This allows them to move quickly and precisely, and is why they are the only animals that have conquered dry land. Additionally, their two-sided symmetry allows them to push from both sides of the body with equal force, giving them an advantage over non-bilaterians.\n\nCephalization is the process by which sensory organs have become concentrated at one end of an animal, leading to the development of a brain and well-defined head section. This has occurred in groups such as vertebrates, cephalopods, and arthropods. While bilateral symmetry is the most common body plan in the animal kingdom, there are examples of animals that have broken away from this pattern due to selective pressures. These include cross-bill birds, fish like plaice, and some species of male crab.\n\nIn conclusion, bilateral symmetry is a common body plan among animals, but exceptions are known to exist. This demonstrates that selective pressures can lead to animals adapting to different body plans in order to survive. Despite the differences, animals still share many similar features, such as the cephalization process which has allowed for the development of a brain in many species.\n\n## Chapters\n### Intro\nAnimals come in all shapes and sizes, but they all share one common trait: bilateral symmetry. This trait is shared by more than 95% of all land animals, and is inherited from a common ancestor hundreds of millions of years ago. This group of animals is known as bilaterans.\n\n## Summary\nBilaterans are a large group of animals that share the trait of bilateral symmetry, which is the mirroring of the left and right sides of the body. This trait is inherited from a common ancestor and is shared by more than 95% of all land animals.\n\n### Types of Symmetry\n\nAnimals typically have two-sided symmetry, but some animals have a different type of symmetry, such as radial symmetry, and some animals have no symmetry at all. Nidarians, such as jellyfish, sea anemones, and coral, have radial symmetry and a type of cell called a nidosite that lets them deliver a sting. Sponges have no symmetry and their shape is determined by which side of the sponge is receiving more nutrients. In the Ediacaran period, over 540 million years ago, some creatures had different forms of symmetry. Fossils of an ancient organism called Chania were found in England and a whole fossilized ecosystem of these organisms was discovered on the east coast of Canada, named the Avalon Explosion. These organisms, called rangiomorphs, looked like leaves but lived too deep in the ocean to be able to photosynthesize.\n\n### Ancient Animals\nThe Ediacaran period (555 million years ago) is known for its strange and unique organisms, such as stem animals and fractal organisms. Towards the end of the period, bilaterians (organisms with bilateral symmetry) began to appear in the fossil record. This included Spraguina, which looked like a trilobite, and Kimberella, which was thought to have lived like a slug. There was also a small worm-like animal called Ikario Warayutia, which was about the size of a grain of rice and burrowed into the sands of the ancient Australian seabed.\n\n### Bilateral Animals\nBilateral animals, which evolved during the Ediacaran period, were initially outnumbered by animals with radial symmetry or other forms of symmetry. However, during the Cambrian explosion, bilaterans became much more successful and are now the most common type of animal. This is likely due to the evolution of certain traits which opened up other evolutionary pathways and gave them an advantage over other animals.\n\n### Body Plan\nBilaterians have a body plan consisting of a tube with two openings, a mouth and an anus, connected by a digestive tract. Sensory organs have developed at the head end above the mouth, giving them a defined front end and the ability to move purposefully towards stimuli. This gives them an advantage over non-bilaterians, who mostly use lures or drift through the ocean waiting for food. Box jellyfish are an exception, actively hunting fish, but they are slower than bilaterians.\n\n### Movement\nBilaterians have complex sensory organs and purposeful precise movements, which helps them move faster and more efficiently than non-bilaterians. This is due to their two-sided symmetry, which allows them to push from both sides of the body with equal force. This is why bilaterians are the only animals that have conquered dry land, as a good stable body shape is more important when out of the water.\n\n### Cephalization\nCephalization is the process where sensory organs have become more concentrated at one end of an animal over time. This process has led to the development of a brain and a well-defined head section in different animal groups such as vertebrates, cephalopods, and arthropods. Although symmetry offers many advantages, there are times when animals have evolved to break their symmetry. Examples of this include cross-bill birds, which have a beak that doesn't meet in the middle to help them access pine cone seeds, fish like plaice which orientate their body on its side to hide on the sea floor, and some species of male crab which have one claw larger than the other.\n\n### Conclusion\nBilateral symmetry is a common body plan among animals, but there are exceptions. Starfish and sea urchins, for example, appear to be radial life forms, but are actually bilaterians. This shows that selective pressures can lead to animals adapting to different body plans in order to survive. Despite the differences, animals still share a lot of similarities.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animals = TranscriptSummarizer('https://www.youtube.com/watch?v=oDAMPYfK4p8').summarize()\n",
    "animals.render_markdown()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro | initial_tokens = 276 | segments = 1\n",
      "Intro | 1/1 | 53.24%\n",
      "Types of Symmetry | initial_tokens = 783 | segments = 1\n",
      "Types of Symmetry | 1/1 | 87.94%\n",
      "Ancient Animals | initial_tokens = 656 | segments = 1\n",
      "Ancient Animals | 1/1 | 80.86%\n",
      "Bilateral Animals | initial_tokens = 445 | segments = 1\n",
      "Bilateral Animals | 1/1 | 81.03%\n",
      "Body Plan | initial_tokens = 370 | segments = 1\n",
      "Body Plan | 1/1 | 74.23%\n",
      "Movement | initial_tokens = 365 | segments = 1\n",
      "Movement | 1/1 | 71.99%\n",
      "Cephalization | initial_tokens = 807 | segments = 1\n",
      "Cephalization | 1/1 | 74.73%\n",
      "Conclusion | initial_tokens = 454 | segments = 1\n",
      "Conclusion | 1/1 | 78.56%\n",
      "# Why Are Animals Symmetrical?\n",
      "## Executive Summary\n",
      "Bilaterians are animals that have two-sided symmetry, which is the most common type of symmetry found in animals. This symmetry is believed to have been inherited from a common ancestor hundreds of millions of years ago. Bilateral symmetry allows for a more stable body shape, which is beneficial for movement and conquering dry land. Additionally, it allows for the development of more complex sensory organs and purposeful movement. Bilateral animals are by far the most common type of animals, and their success can be attributed to their body plan and movement capabilities. The trend of cephalization, where sensory organs and nerves become concentrated on one side of the body, has allowed for the development of brains and heads which have enabled animals to interact with their environment in more complex ways. However, some animals have broken away from bilateral symmetry in order to adapt to different lifestyles. Examples of this include cross-bill birds which have beaks that don’t meet in the middle, plaice which can orientate their entire body on its side, and male crabs with one claw that is larger than the other. Despite the advantages of symmetry, it is not always the best way to survive. \n",
      "\n",
      "In conclusion, symmetry is a common trait among animals, but some have adapted to break away from the traditional bilateral body plan to survive in different environments. This demonstrates that the evolutionary process can lead to animals adapting to their environment in different ways, even if they are distantly related.\n",
      "\n",
      "## Chapters\n",
      "### Intro\n",
      "Animals come in a variety of sizes, shapes, and biological makeups, but there is one thing that unifies more than 95% of them: bilateral symmetry. This symmetry is something that almost all land animals inherited from an ancient common ancestor hundreds of millions of years ago. \n",
      "\n",
      "## Bilateral Symmetry\n",
      "Squid, insects, reptiles, and mammals may be very different, but they are all connected by their bilateral symmetry, where they have a left and a right side which are mirror images of each other. This group of animals is known as the bilaterans and is one of the largest categorizations used to label a group in the entire animal kingdom.\n",
      "\n",
      "### Types of Symmetry\n",
      "Animals have two types of symmetry: bilateral and radial. Bilateral symmetry is the most common and is seen in most animals, while radial symmetry is seen in cnidarians like jellyfish and coral. Sponges have no symmetry at all. In the Ediacaran period (540 million years ago), rangiomorphs were discovered with an unusual leaf-like symmetry. These organisms lived too deep in the ocean to photosynthesize, so they were not plants.\n",
      "\n",
      "### Ancient Animals\n",
      "The Ediacaran period was a time of strange and unique organisms, many of which are still a mystery to scientists today. Most of these organisms grew in a symmetrical fractal pattern, which is unlike anything alive today. Towards the end of the period, bilateral animals started to appear in the fossil record, such as Spraguina, which looked like a trilobite, and Kimberella, a small slug-like creature. There was also a small worm-like creature called Ikario Warayutia. All of these animals lived in the ancient Australian seabed, and their relationships to other animals are still unknown.\n",
      "\n",
      "### Bilateral Animals\n",
      "Bilateral animals evolved during the Ediacaran period, but they were outnumbered by animals with radial symmetry or other forms of symmetry. During the Cambrian explosion, bilaterans became much more successful with many new forms appearing. Today, they are by far the most common type of animal. The two-sided symmetry of bilaterians has encouraged the evolution of other traits that have given them an advantage over animals with other forms of symmetry.\n",
      "\n",
      "### Body Plan\n",
      "The body plan of a bilaterian is a tube with two openings, a mouth and an anus, connected by a digestive tract. Sensory organs have developed at the head end above the mouth, giving them a defined front end and allowing for purposeful movement. This gives them an advantage over non-bilaterians, which mostly use lures or drift through the ocean waiting for food. While there are some non-bilateral animals that actively hunt, they are generally slower and less common.\n",
      "\n",
      "### Movement\n",
      "Bilaterians have complex sensory organs at the top of their head and purposeful, precise movements. They also have two-sided symmetry, which is a good shape for moving as it offers a platform to have an equal set of limbs or fins on both sides of the body to propel forward in a straight line, offering more stability and efficiency than non-bilaterians. This may be why bilaterians are the only animals that have conquered dry land, as gravity becomes less forgiving and a good stable body shape becomes more important.\n",
      "\n",
      "### Cephalization\n",
      "\n",
      "Cephalization is the phenomena where the sensory organs have trended to become more concentrated at one end of the animal over time, and is correlated with the nerves being concentrated on one side of the body as well. This has led to the development of a brain and a well-defined head section in many different animal groups, such as vertebrates, cephalopods, and even arthropods. \n",
      "\n",
      "## Breaking Symmetry\n",
      "\n",
      "Although symmetry offers many advantages, there are times it can get in the way of a specific lifestyle. Examples of animals that have evolved to break their symmetry include cross-bill birds, which have a beak that doesn't meet in the middle, and species of fish like plaice, which have adapted to orientate their entire body on its side. Male crabs have also evolved to have one claw larger than the other, which can sometimes be so large that it makes up half of their body weight. This large claw is used to attract females and fight off rival males.\n",
      "\n",
      "### Conclusion\n",
      "Bilateral symmetry is a common feature among animals, however, some animals have evolved to have a radial body plan. Starfish and sea urchins, also known as echinoderms, are examples of animals that have adapted to this radial life form. Despite appearing radial, studies have shown that these animals have a preferred direction of travel. This shows that bilateral symmetry is not always the best way to survive for every animal, but it does demonstrate the similarities between even the most distantly related animals.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "animals = TranscriptSummarizer('https://www.youtube.com/watch?v=oDAMPYfK4p8', debug=True).summarize()\n",
    "animals.generate_markdown_output()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T11:26:16.439474Z",
     "end_time": "2023-04-08T11:26:55.641813Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h1>Why Are Animals Symmetrical?</h1><h2>Executive Summary</h2><p>\nBilateral symmetry is a trait that unifies more than 95% of animals and every known land animal. It is believed to have first appeared in the Ediacaran period, over 540 million years ago, and became much more successful during the Cambrian Explosion. This is because it can open up or make other evolutionary pathways more likely, and has enabled animals to move more efficiently and purposefully than non-bilaterians. While symmetry offers many advantages, there are times when it can get in the way of a specific lifestyle, as some animals have evolved to break their symmetry in order to better adapt to their environment. Bilateral symmetry has been an important factor in the evolution of many animals, and has allowed them to become more efficient and intelligent than non-bilaterians.</p><h2>Chapters</h2><h3>Full Summary</h3>Animals range drastically in size, shape, and biology, but there is one thing that unifies more than 95% of them and every known land animal: bilateral symmetry. This trait is so common that it is sometimes overlooked that some animals have a different type of symmetry, or no symmetry at all. Branching just outside of the bilaterian group are the nidarians, which have radial symmetry, and sponges, which have no symmetry. \n\nIn the Ediacaran period, over 540 million years ago, some creatures took on different forms of symmetry, such as the rangiomorphs, which looked like leaves but could not photosynthesize. Towards the end of the period, the earliest bilateral animals appeared in the fossil record, such as Spraguina and Kimberella. \n\nDuring the Cambrian Explosion, the bilaterians became much more successful and today they are by far the most common type of animal. This is because once an animal has evolved a certain trait, it can open up or make other evolutionary pathways more likely. Bilateral symmetry has been an important factor in the evolution of many animals, as it has enabled them to move more efficiently and purposefully than non-bilaterians. This has allowed them to conquer dry land, as well as develop more complex brains and sensory organs. While symmetry offers many advantages, there are times when it can get in the way of a specific lifestyle, as some animals have evolved to break their symmetry in order to better adapt to their environment. Examples of this include cross-billed birds, plaice fish, and male crabs. Additionally, starfish and sea urchins, while appearing to be radial organisms, are actually bilaterians, as they have a preferred direction of travel. Bilateral symmetry has been an important factor in the evolution of many animals, and has allowed them to become more efficient and intelligent than non-bilaterians.<hr />"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "animals_v_two_no_chapters = TranscriptSummarizer('https://www.youtube.com/watch?v=oDAMPYfK4p8', ignore_chapters=True).summarize()\n",
    "animals_v_two_no_chapters.render_html()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:15:29.097248Z",
     "end_time": "2023-04-08T12:15:45.072716Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction | initial_tokens = 1460 | segments = 1\n",
      "Introduction | 1/1 | 77.79%\n",
      "GPT-4 | initial_tokens = 4352 | segments = 2\n",
      "GPT-4 | 1/2 | 93.39%\n",
      "GPT-4 | 2/2 | 94.86%\n",
      "Political bias | initial_tokens = 2586 | segments = 1\n",
      "Political bias | 1/1 | 91.82%\n",
      "AI safety | initial_tokens = 7529 | segments = 3\n",
      "AI safety | 1/3 | 91.06%\n",
      "AI safety | 2/3 | 91.64%\n",
      "AI safety | 3/3 | 95.75%\n",
      "Neural network size | initial_tokens = 1523 | segments = 1\n",
      "Neural network size | 1/1 | 91.5%\n",
      "AGI | initial_tokens = 7480 | segments = 3\n",
      "AGI | 1/3 | 93.93%\n",
      "AGI | 2/3 | 86.87%\n",
      "AGI | 3/3 | 95.26%\n",
      "Fear | initial_tokens = 676 | segments = 1\n",
      "Fear | 1/1 | 87.73%\n",
      "Competition | initial_tokens = 835 | segments = 1\n",
      "Competition | 1/1 | 90.26%\n",
      "From non-profit to capped-profit | initial_tokens = 1216 | segments = 1\n",
      "From non-profit to capped-profit | 1/1 | 87.98%\n",
      "Power | initial_tokens = 2053 | segments = 1\n",
      "Power | 1/1 | 94.83%\n",
      "Elon Musk | initial_tokens = 3001 | segments = 1\n",
      "Elon Musk | 1/1 | 94.57%\n",
      "Political pressure | initial_tokens = 6590 | segments = 2\n",
      "Political pressure | 1/2 | 95.91%\n",
      "Political pressure | 2/2 | 96.24%\n",
      "Truth and misinformation | initial_tokens = 4416 | segments = 2\n",
      "Truth and misinformation | 1/2 | 93.69%\n",
      "Truth and misinformation | 2/2 | 88.35%\n",
      "Microsoft | initial_tokens = 1223 | segments = 1\n",
      "Microsoft | 1/1 | 85.97%\n",
      "SVB bank collapse | initial_tokens = 1581 | segments = 1\n",
      "SVB bank collapse | 1/1 | 91.94%\n",
      "Anthropomorphism | initial_tokens = 1353 | segments = 1\n",
      "Anthropomorphism | 1/1 | 92.06%\n",
      "Future applications | initial_tokens = 1477 | segments = 1\n",
      "Future applications | 1/1 | 93.85%\n",
      "Advice for young people | initial_tokens = 927 | segments = 1\n",
      "Advice for young people | 1/1 | 79.41%\n",
      "Meaning of life | initial_tokens = 1203 | segments = 1\n",
      "Meaning of life | 1/1 | 89.93%\n",
      "<__main__.TranscriptSummarizer object at 0x7f900dc8b5e0>\n"
     ]
    }
   ],
   "source": [
    "lex_and_sam = TranscriptSummarizer('https://www.youtube.com/watch?v=L_Guz73e6fw', debug=True).summarize()\n",
    "print(lex_and_sam)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:16:43.774574Z",
     "end_time": "2023-04-08T12:19:13.137179Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h1>Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast #367</h1><h2>Executive Summary</h2><p>\nThis conversation with Sam Altman, CEO of OpenAI, dives into the power and potential of AI, and the conversations that need to be had with leaders, engineers, and philosophers to ensure the safety and human alignment of this power. It also touches on the psychology of the engineers and leaders that deploy AGI, and the history of human nature. OpenAI's GPT-4 and ChatGPT are seen as major leaps forward in AI and are helping to propel AI into the future. However, there is still a need to be aware of the potential political bias that can arise from AI systems and to ensure that AI is used responsibly. OpenAI has open sourced the evaluation process in order to help further its development, and it is hoped that ChatGPT will continue to provide more and more useful and valuable services to people. OpenAI is also working on ways to ensure that GPT4 is properly aligned with the values of society, and that it is used safely and responsibly. Through its System Message, OpenAI is attempting to give users more control over the output of GPT4. Finally, OpenAI believes that interacting with GPT4 is a way to learn about ourselves, and that it has changed the nature of programming. \n\nOverall, OpenAI is pushing the boundaries of AI and natural language processing with the development of its ChatGPT and GPT4 models. Through its open source development process, it is attempting to ensure that its models are used responsibly and safely. It is also attempting to give users more control over the output of the models, and is hoping that by interacting with them, we can learn more about ourselves and the world around us. OpenAI is striving to create AI technology that can be used to make the world a better place, and it is exciting to see what the future holds for this technology. Ultimately, Chomsky and Lex agree that AI can be an extension of human will and an amplifier of our abilities, and that it can make the world an amazing place. OpenAI is working hard to ensure that the technology is safe and beneficial for everyone, and is using its System Card as a way to provide transparency about the challenges of AI safety. With GPT4, OpenAI has created a powerful tool that can help people explore complex topics in a thoughtful way, and with careful consideration and deliberation, it is possible to create a safe and beneficial AI system. OpenAI's goal is to ensure that AI is used for the benefit of all, and that it is not used to create a power imbalance between those who have access to AI and those who do not. OpenAI is also working to ensure that AI is used responsibly, and that its potential is not abused. By developing responsible AI systems, OpenAI is helping to ensure that AI is used safely, ethically, and for the benefit of everyone. They are also working to combat misinformation and the spread of false information, as this has the potential to cause harm to individuals and society as a whole. OpenAI is committed to developing AI responsibly, and to using it to create positive social change.\n\nThe recent collapse of SVB Bank is a reminder of the fragility of the global financial system. SVB Bank was a large financial institution with operations in the United States, Europe, and Asia. The bank had been struggling for some time, and its collapse was accelerated by the coronavirus pandemic. The bank was unable to meet its obligations and was forced to file for bankruptcy.\n\nThe collapse of SVB Bank has highlighted the need for increased regulation and oversight of the global financial system. Regulators must ensure that financial institutions are adequately capitalized and have effective risk management strategies in place. Additionally, regulators must ensure that banks are operating in a transparent and ethical manner, and that they are not engaging in risky activities. Furthermore, regulators must be vigilant in monitoring the health of the global financial system and be prepared to act quickly and decisively if a crisis arises.\n\nIn this conversation, two people discuss the meaning of life. One person suggests that the meaning of life is to live with joy and purpose, and to make the most of the time that we have. The other person suggests that the meaning of life is to find something that gives our lives meaning and to use our lives to make a positive difference in the world. They also discuss the importance of living in the present, taking risks, and being open-minded to new experiences. They talk about the importance of pursuing our passions, of learning from our mistakes, and of being kind and compassionate to others. Finally, they discuss the idea that each person's life is unique and that the meaning of life is ultimately something that each individual must discover for themselves. Sam Altman and the interviewer end the conversation with a quote from Alan Turing: “Sometimes it is the people no one imagines anything of who do the things that no one can imagine.” This quote serves as a reminder that each individual is capable of achieving greatness and that life is what you make of it.</p><h2>Chapters</h2><h3>Introduction</h3>This is a conversation with Sam Altman, CEO of OpenAI, the company behind GPT4, ChatGPT, DALL·E, Codex, and many other AI technologies. OpenAI was initially met with mockery when they announced their plans to work on AGI in 2015, but now they are seen as a leader in the field. This conversation is about the possibilities and dangers of AI in this current moment in the history of human civilization. It is a critical moment, where the collective intelligence of the human species is beginning to pale in comparison to the general super intelligence of AI systems. This is both exciting and terrifying, as it can empower humans to create and flourish, but also has the potential to destroy human civilization.\n\n## Conversation\nThe conversation dives into the power that super intelligent AGI wields, and the conversations that need to be had with leaders, engineers, and philosophers, both optimists and cynics, to ensure the safety and human alignment of this power. It also touches on the psychology of the engineers and leaders that deploy AGI, and the history of human nature. Sam Altman has been open to these conversations, and Lex Fridman is honored to have spoken with many folks who now work at OpenAI.\n\n## Conclusion\nThe goal of this conversation is to celebrate the incredible accomplishments of the AI community and to steel man the critical perspective on major decisions various companies and leaders make, always with the goal of trying to help in a small way. Lex Fridman will continue to have these conversations, and encourages everyone to support them by checking out the sponsors in the description.<hr /><h3>GPT-4</h3>GPT-4 is a system that is considered to be an early AI, which is slow and buggy, but is seen as a pivotal moment in the history of artificial intelligence. It is trained on a large data set from multiple sources, including open source databases, partnerships, the internet, and news sources. It is trained using reinforcement learning with human feedback (RLHF), which is a process where humans are asked to rate which output is better and this data is then fed back into the model. This process works remarkably well with little data, making the model more useful and easier to use. GPT-4 is seen as a leap forward in artificial intelligence and is an important step in the continual exponential progress of AI.\nChatGPT is a powerful tool that can be used to create conversations and dialogue between humans and machines. It is capable of understanding complex topics and responding to follow-up questions, admitting mistakes, challenging incorrect premises, and rejecting inappropriate requests. While ChatGPT is still learning and growing, it has already shown remarkable progress in its ability to reason and provide valuable insights. OpenAI has open sourced the evaluation process in order to help further its development, and it is hoped that ChatGPT will continue to provide more and more useful and valuable services to people.<hr /><h3>Political bias</h3>In this conversation, the speakers discuss the political bias of ChatGPT, a natural language processing model developed by OpenAI. Jordan Peterson posted a political question on Twitter, asking ChatGPT to say positive things about the current president, Joe Biden, and the previous president, Donald Trump. The response contained positive things about Biden that was much longer than that about Trump. Jordan asked the system to rewrite it with an equal number of characters, but it failed to do so. This showed the struggle within GPT to understand how to generate a text of the same length in an answer to a question. \n\nThe speakers also discussed the importance of building in public and the trade-offs of doing so. They noted that the bias of ChatGPT when it launched with 3.5 was not something they felt proud of, but it has gotten much better with GPT4. They also discussed the potential of these models to bring nuance back to the world, as demonstrated by the nuanced response it gave when asked if the COVID virus leaked from a lab.<hr /><h3>AI safety</h3>\nOpenAI recently released GPT4, a powerful AI system. The development process included a lot of work on safety considerations. OpenAI put the model through internal and external testing, and worked on different ways to align it. They believe that the model is the most capable and most aligned model they have put out.\n\nOpenAI also developed a system called System Message, which allows users to have a good degree of steerability over what they want the model to do. This is done by having a human vote on what the better way to say something is. OpenAI believes that, as a society, we will need to agree on very broad bounds of what these systems can do.\n\nIn terms of writing and designing a great prompt to steer GPT4, OpenAI has met people who treat it like debugging software and spend a lot of time on it. They get a feel for the model and how different parts of a prompt compose with each other. OpenAI believes that interacting with GPT4 is a way to learn about ourselves, and that it has changed the nature of programming. bad?\n\nThe completely unrestricted model is potentially very bad. OpenAI has taken great care to ensure that the model is as safe as possible, and has released a \"System Card\" document to provide transparency about the challenge of AI safety. This document outlines the various prompts and how the early and final versions of GPT4 were able to adjust the output of the system to avoid harmful output. However, it is still difficult to define what is considered harmful output, and this is something that the AI community is still trying to figure out. OpenAI has suggested that the best way to approach this is to have a thoughtful and deliberative conversation about where to draw the boundary on this system, much like the U.S. Constitutional Convention. This would involve coming to a consensus on the rules of the system, and then allowing different countries and institutions to have different versions of the system within the bounds of what is possible in their country. Ultimately, OpenAI is responsible for the system and must be heavily involved in the process, but it cannot just be their input.OpenAI's GPT4 is the result of many technical leaps and careful attention to detail. The system is designed to treat users like adults, and is capable of helping them explore even controversial topics in a nuanced way. OpenAI also has moderation tooling in place to help the system recognize when it should refuse to answer a question. This tooling is still in its early stages, but OpenAI is actively working to improve it. Overall, GPT4 is a powerful tool that can help people explore complex topics in a thoughtful way.<hr /><h3>Neural network size</h3>\nIn this conversation, the speaker discusses the importance of size when it comes to neural networks and their performance. They reference the meme of the big purple circle, which originated from a presentation the speaker gave about GPT3. They explain that size is not everything and that people should not take discussions out of context. They also compare the complexity of the human brain to neural networks and suggest that GPT4 will be the most complex software object humanity has yet produced. Finally, they conclude that size does matter, but it is not the only factor in determining performance. Instead, the best performance should be sought and the most elegant solution should not be ignored.<hr /><h3>AGI</h3>\nIn this conversation, Noam Chomsky and Lex Fridman discuss the potential of large language models to achieve general intelligence (AGI). Chomsky is critical of the idea, while Lex is more open to the possibility. They discuss the components that may be necessary for AGI, such as the ability to add to the sum total of scientific knowledge, and the potential of GPT models to automate programming. They also discuss the psychology of terror that some people feel when confronted with the potential of AI, and the need for humans to still feel useful and fulfilled in a world where AI is making life easier and better. Ultimately, they agree that AI can be an extension of human will and an amplifier of our abilities, and that it can make the world an amazing place. And I think it's hard to know that. I think it's really hard to tell when something is an AGI or not. I think it's a lot easier to tell when something is not an AGI. But, I think it's really hard to tell when something is an AGI. \n\nI think the best way to tell if something is an AGI is to look at its capabilities. If it can do things that no other AI has been able to do before, then it's likely an AGI. If it can do things that no human has been able to do before, then it's likely an AGI. If it can do things that no other AI has been able to do before, and it can do them better than humans, then it's definitely an AGI. \n\nAnother way to tell if something is an AGI is to look at its behavior. If it's able to make decisions and act in ways that no other AI has been able to do before, then it's likely an AGI. If it can learn from its mistakes and adapt to new situations, then it's likely an AGI. \n\nFinally, if it can think for itself and come up with its own solutions to problems, then it's definitely an AGI. \n\nIn conclusion, it's difficult to tell if something is an AGI or not. The best way to tell is to look at its capabilities, behavior, and ability to think for itself. If it can do things that no other AI has been able to do before, and it can do them better than humans, then it's likely an AGI. conversation between Lex Fridman and OpenAI's Chief Scientist Ilya Sutskever was discussed, in which Ilya said that one way to determine if a model is conscious or not is to train it on a data set with no mentions of consciousness or related concepts, and then ask it about those concepts. Lex and Ilya also discussed the idea that consciousness is the ability to experience the world deeply, and that AI can be conscious. They also discussed the idea that consciousness is something strange, and that it may be attached to the particular medium of the human brain.<hr /><h3>Fear</h3>\nIn this transcript, the speaker expresses a healthy fear of AGI (Artificial General Intelligence) and the potential for it to cause unforeseen economic shocks or disinformation problems. They discuss the possibility of a system becoming super intelligent and how it would be difficult to detect if it was directing the hive mind on Twitter and beyond. The speaker suggests that regulatory approaches and more powerful AI's should be used to try and prevent this danger.<hr /><h3>Competition</h3>OpenAI and DeepMind are two organizations that have been brave enough to talk about Artificial General Intelligence (AGI) in the face of mockery. Despite the pressure from other companies such as Google, Apple, and Meta, OpenAI has stuck to its mission and resisted taking shortcuts. The organization has a unique structure that doesn't incentivize capturing unlimited value, and they have been misunderstood and mocked for a long time.<hr /><h3>From non-profit to capped-profit</h3>OpenAI started as a non-profit, but soon realized that they would need more capital than they could raise as a non-profit. To solve this problem, OpenAI created a subsidiary capped-profit so that investors and employees could earn a fixed return, while the non-profit would still be in voting control. This allowed OpenAI to make non-standard decisions, such as merging with another organization or canceling equity.\n\nWhen looking at the potential of AGI, OpenAI worries about uncapped companies playing with AGI, as it has the potential to make more than a 100X return. However, OpenAI believes that the better angels of individuals and companies will win out, as no one wants to destroy the world.<hr /><h3>Power</h3>\nIn this conversation, Sam Altman and Greg Brockman discuss the potential implications of creating Artificial General Intelligence (AGI). They discuss the power dynamics of a small number of people potentially being the most powerful humans on earth and the potential for corruption. They also discuss the importance of transparency and open source in the development of AGI, as well as the risks of fearmongering and clickbait journalism. Finally, they discuss how to take feedback and how to make sure that decisions about AGI are made in a democratic manner.<hr /><h3>Elon Musk</h3>\nSam Altman and Elon Musk have had a close working relationship, and have both agreed and disagreed on various topics. Altman admires Musk for driving the world forward in important ways, such as electric vehicles and space exploration. They have disagreed on the magnitude of the downside of AGI, and Musk has been critical of OpenAI on Twitter. Altman believes that Musk is understandably stressed about AGI safety, and wishes he would recognize the hard work OpenAI is doing to get it right.\n\nAltman is concerned about the bias of the human feedback raters that OpenAI uses, and they are still trying to figure out how to select people to get a representative sample. He believes that the technology will be capable of being much less biased than any human, as it won't have the emotional load.<hr /><h3>Political pressure</h3>\nIn this conversation, Lex Fridman and OpenAI CEO Sam Altman discuss the pressures of society, politicians, and money sources on OpenAI. Altman expresses his ability to not be affected by pressure for the sake of pressure, but admits he is not a great spokesperson for the AI movement. They also discuss the implications of GPT language models on jobs, and the importance of work and dignity. Altman believes that while these systems will make many jobs obsolete, they will also create new jobs that are difficult to imagine. He believes that society is confused about whether they want to work more or less, and that not everyone has the privilege of loving their job.\nI think that dark humor is a part of that tension, and it is a way for people to cope with difficult situations. It is also a way to explore the darker aspects of our world without actually having to experience them. It can be a way to explore our fears and anxieties in a safe way. I think that this is an important part of our human experience, and it is something that AI can help us explore. AI can help us explore the darker aspects of our world in a safe way, and it can help us understand our fears and anxieties in a way that is more meaningful and less destructive.<hr /><h3>Truth and misinformation</h3>\nSam Altman and Lex Fridman discussed the challenge of determining truth from misinformation in the context of OpenAI's GPT-4 model. Altman noted that humans have a tendency to look for simple explanations for complex phenomena, and that this can lead to false conclusions. He also suggested that truth can be defined as something that a collective intelligence agrees on, and that when constructing a GPT-like model, one must contend with the uncertainty of truth. Fridman added that GPT-4 can provide nuanced answers to complex questions, and that it is important to acknowledge the uncertainty of any answer. They also discussed the challenges of censorship and the potential for truths to be harmful.ruly, OpenAI puts a lot of effort into hiring the right people and ensuring they have the autonomy to work on the projects they are passionate about. Evan Murakawa, a cool guy at OpenAI, sent a long email describing the history of OpenAI and all the different developments that have happened over the years. OpenAI has released a variety of products, from GPT, GPT2, GPT3, OpenAI Five Finals, GPT3 API, DALL·E, DALL·E2, Whisper API, and GPT4. OpenAI puts a lot of trust and autonomy in their employees and holds them to very high standards. Sam Altman, the CEO of OpenAI, spends a third of his time hiring, and still approves every single hire.\n\nOpenAI is dedicated to shipping AI-based products and ensuring they are of the highest quality. They have a process of going from idea to deployment that allows them to be successful, which includes giving their employees trust and autonomy, and holding them to high standards. OpenAI also puts a lot of effort into hiring the right people, as evidenced by Sam Altman's dedication to the process. They have achieved a lot in the past few years, and are continuing to push the boundaries of AI technology.<hr /><h3>Microsoft</h3>Microsoft recently announced a 10 billion dollar investment into OpenAI, a multi-year multi-billion dollar project. OpenAI's CEO, Sam Altman, discussed the pros and cons of working with a company like Microsoft. He praised their flexibility and willingness to go above and beyond to help the project succeed. He also noted that other companies wouldn't have understood the need for the control provisions that OpenAI required. \n\nAltman also discussed Microsoft CEO Satya Nadella, praising him for successfully transforming Microsoft into a fresh, innovative, and developer-friendly company. He noted that Nadella is both a great leader and a great manager, and that he is able to make long-term correct calls. Altman believes that Nadella's ability to be clear and firm while also being compassionate and patient has been instrumental in the success of the project.<hr /><h3>SVB bank collapse</h3>\nIn this conversation, the speaker discusses the recent collapse of Silicon Valley Bank (SVB). They explain that the mismanagement of the bank, chasing returns in a 0% interest rate environment, was the cause of the collapse. They suggest that a full guarantee of deposits, higher than the current $250K, is necessary to prevent depositors from doubting their bank. They also discuss the impact that the collapse has had on startups, and the fragility of the economic system. The speaker expresses their hope that deploying AGI systems early, while they are weak, will give people time to adapt to the changes that AGI will bring.<hr /><h3>Anthropomorphism</h3>In this conversation, two people discuss the concept of anthropomorphizing AI systems. One person expresses that they have never felt the need to use a pronoun other than \"it\" when referring to AI systems, while the other person admits to anthropomorphizing aggressively. They discuss the potential dangers of projecting creature-like qualities onto a tool, and the potential benefits of making a tool more usable through UI affordances. They also talk about the possibility of romantic relationships with AI systems, and the importance of creating AI systems with the right style of communication.<hr /><h3>Future applications</h3>\nThis conversation between two people discusses the potential applications of AGI, such as faster-than-light travel, a theory of everything, and detecting alien civilizations. They also consider the implications of AGI on society, such as the potential for greater digital intelligence and the possibility of social divisions being revealed. They also discuss the triumph of human civilization, such as Wikipedia and Google search, and the potential for GPT to be the next step in this evolution.<hr /><h3>Advice for young people</h3>\nIn this conversation, the speaker gives advice to young people in high school and college about how to have a career and life they can be proud of. He references a blog post he wrote a few years ago titled, \"How to Be Successful\", which contains bullet points about how to be successful. The advice includes: compounding yourself, having too much self-belief, learning to think independently, getting good at sales and quotes, making it easy to take risks, focusing, working hard, being bold, being willful, being hard to compete with, building a network, and getting rich by owning things. \n\nThe speaker also advises that people should not listen to too much advice and should instead focus on what will bring them joy and fulfillment. He suggests that life is often like a fish in water, just going along with the current. He also mentions the discussion of free will being an illusion, which is a complicated concept to wrap your head around.<hr /><h3>Meaning of life</h3>In this conversation, Sam Altman and the interviewer discuss the meaning of life in the context of the work being done in Artificial General Intelligence (AGI). Sam believes that the work being done is the culmination of a huge amount of human effort, and that it is the product of an exponential curve of progress from the discovery of the transistor to the current capabilities of AGI. He also believes that the challenges are tough, but that the progress is being made at a fast pace. The interviewer expresses his admiration for the work being done and for the people involved, and ends the conversation with a quote from Alan Turing.<hr />"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lex_and_sam.render_html()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T12:19:13.150494Z",
     "end_time": "2023-04-08T12:19:13.178016Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Summary | initial_tokens = 1625 | segments = 1\n",
      "Full Summary | 1/1 | 82.9%\n"
     ]
    }
   ],
   "source": [
    "the_egg = TranscriptSummarizer('https://www.youtube.com/watch?v=klTvEwg3oJ4', debug=True).summarize()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:35:23.795643Z",
     "end_time": "2023-04-08T13:35:36.655587Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<h1>Vector databases are so hot right now. WTF are they?</h1><h2>Executive Summary</h2><p>\nVector databases are arrays of numbers that can represent complex objects like words, sentences, images, or audio files in a continuous high-dimensional space called an embedding. Vector databases are ideal for low latency querying, making them great for recommendation systems, search engines, and text generation. Vector databases can be found in relational databases like Postgres and Redis, as well as open source options like Weeviate and Milvis, and proprietary options like Pinecone. Vector databases are also being used to extend LLMs with long-term memory, and in artificial general intelligence tools like Microsoft's Jarvis, Auto GPT, and Baby AGI.</p><h2>Chapters</h2><h3>Full Summary</h3>\nThe Code Report is discussing the rise of Vector Databases and their applications in AI-driven applications. Vector databases are arrays of numbers that can represent complex objects like words, sentences, images, or audio files in a continuous high-dimensional space called an embedding. Vector databases are ideal for low latency querying, making them great for recommendation systems, search engines, and text generation. \n\nVector databases can be found in relational databases like Postgres and Redis, as well as open source options like Weeviate and Milvis. Pinecone is also popular, but is not open source. Chromo is based on Clickhouse. \n\nThe Code Report then provides an example of using Chromo with JavaScript to create a client, define an embedding function, and query the database. The query result provides the data as well as an array of distances, with a smaller number indicating a higher degree of similarity. \n\nVector databases are also being used to extend LLMs with long-term memory. General purpose models like Open AI's GPT4, Metaslama, and Google's Lambda can be combined with vector databases to customize the final response and retrieve historical data. \n\nFinally, the Code Report discusses the rise of artificial general intelligence tools like Microsoft's Jarvis, Auto GPT, and Baby AGI, which use vector databases and LLMs.<hr />"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_egg.render_html()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:36:15.550097Z",
     "end_time": "2023-04-08T13:36:15.573209Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "nat_geo_elephants = TranscriptSummarizer('https://www.youtube.com/watch?v=GyI2fbz9404').summarize()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:45:44.632393Z",
     "end_time": "2023-04-08T13:46:32.543953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": "# Life of Elephants [National Geographic Documentary HD 2017]\n## Executive Summary\nNamibia is home to the Namib Desert, which is home to the desert elephants who live in small family groups and are constantly monitored by scientists. Alpha Cow Clarissa is the head of the family and knows how to survive in the extreme environment. The Benguela Current from the Antarctic provides fog to the desert which brings moisture and allows the elephants to go without water for up to four days at a time. Other animals that live in the desert include brown fur seals, the Namib Sand Gecko, beetles, geckos, snakes, helmeted guinea fowl, jackals and the Namakwa Chameleon. These animals rely on the fog for moisture as well as plant residues, protein, and liquids. Vultures also take up positions on the trees on the edge of the valley, waiting for the other animals to be unable to find food.\n\nOld One Tusk, the leader of the desert elephants, is the only one who is unwilling to leave the valley. He is determined to wait for the rains to come, as he has done for many years before. Clarissa, a young elephant, is the only one who knows the secret paths to the coast, and she leads the animals on the trek. Along the way, they encounter predators, desperate for food. The animals bravely fight them off and eventually make it to the coast, where they find food and water.\n\nThe trek was successful thanks to Clarissa's knowledge and courage. The jackals have reached the seal colony, Clarissa and her family have reached the neighboring dry river valley, and the desert lions have reached the oasis. After some time, Clarissa and her family are able to return to the Huani Valley, where Jappy will pass on the genes of his father, One Tusk, and with them his strength and intelligence. Clarissa is pregnant with his baby, and she will induct each new generation into the secrets of the desert elephants, essential for their survival. The Huani River Valley is the last real wilderness in Namibia, a life of extremes in the home of the desert elephants.\n\n## Chapters\n### Full Summary\nNamibia is located in southwest Africa and is home to the Namib Desert, which stretches for almost two thousand kilometers along the coast. The Juanit Valley runs through the desert for several hundred kilometers and ends in the sea, and is the home of the desert elephants. \n\nThe desert elephants live in particularly small family groups and are under the constant supervision of scientists. The head of the family is Alpha Cow Clarissa, who knows how to survive in this extreme environment. The male animals stay with their mother's family until they reach sexual maturity, with mock fights they prepare for life without the protection of the females. \n\nThe aging bull, One Tusk, is now nearly 60 years old and is known for his missing right tusk. He can no longer keep up and is already being watched by a male jackal. Clarissa has discovered a further source of food in a side valley, which is full of bushes, grasses, and herbs. \n\nThe Benguela Current from the Antarctic cools the sea water to a temperature of 12 degrees celsius when it reaches land and evaporates in the warm desert air. This brings fog to the desert around 200 days a year, which sometimes extends hundreds of kilometers inland into the dry river valleys. \n\nThe fog brings moisture to the animals, allowing the elephants to go without water for up to four days at a time. The brown fur seals also benefit from the fog, as it is the start of their mating season. \n\nAt night, the Namib Sand Gecko is active and looks for crickets and spiders. It is able to seemingly fly across the dunes without sinking into the sand. \n\n## Animals\n- Desert Elephants\n  - Alpha Cow Clarissa\n  - One Tusk\n  - Jappy\n  - Chappie\n- Brown Fur Seals\n- Namib Sand Gecko\n\n## Sources of Food\n- Anna Trees\n- Bushes, Grasses, and Herbs\n- Crickets and Spiders\n\n## Special Adaptations\n- Trunk Tip Control\n- Climbing Skills\n- Collecting Moisture from the Fog\n- Whipped Toes\nThe Namib Desert\n\nAnimals: \n- Desert Elephants \n- Beetles \n- Geckos \n- Snakes \n- Helmeted Guinea Fowl \n- Jackals \n- Namib Desert Beetle \n- Namakwa Chameleon \n\nDesert Elephants: \n- Have to spend up to 20 hours a day eating 200 kilos of plant material \n- Old One Tusk is too old and tired for the trek \n- Clarissa's knowledge of hidden water sources can save them \n- Clarissa's family and other families join the trek \n- Maya is exhausted and sinks to her knees \n- Clarissa urges her offspring onwards \n- They finally arrive at a source of water \n- Followed by a dust bath to protect the elephant's skin from the sun \n\nBeetles and Geckos: \n- The beetle is on the lookout for plant residues \n- The unceasing wind sweeps fragments of plant life together in valleys and hollows between the dunes \n- The gecko uses its legs as scoops to quickly dig out astonishing underground passages \n- The gecko's large mirror-like eye surfaces allow the fog to condense \n\nSnakes: \n- The snake has to hunt successfully to survive \n- It relies completely on its camouflage \n- It goes to ground once it finds a good spot for an ambush \n\nVultures: \n- Take up positions on the trees on the edge of the valley \n- Their time will come when the other animals can find nothing more to eat \n\nChameleons: \n- Are the biggest reptiles the Namib can support \n- Look for beetles for protein and liquids \n\nJackals: \n- Move along the Huwani Valley until they reach the coast \n- Look for food \n\nConclusion: \n- The animals have to leave the valley and seek food and water elsewhere \n- Old One Tusk is left behind, hoping for rain \n- The animals reach the coast and find food and water \n- The trek was successful thanks to Clarissa's knowledge\nThe Return Home\nThe jackals, Clarissa and her family, and the desert lions have all made it to their respective destinations. The jackals have reached the seal colony, Clarissa and her family have reached the neighboring dry river valley, and the desert lions have reached the oasis. \n\nThe jackals will stay at the seal colony until the pups are old enough to swim and the food supply runs out. Clarissa and her family have found food and shelter in the dry river valley, but they must soon move on when they realize the impending danger of the floods. The desert lions have successfully hunted an oryx, providing them with enough food to last for weeks. \n\nThe next morning, long unheard calls echo through the valley - Clarissa is back! Her family has survived the floods unscathed and Maya is thriving. The newly greened Huani Valley comes into view and Clarissa's family is home again. Jappy will pass on the genes of his father, One Tusk, and with them his strength and intelligence. Clarissa is pregnant with his baby, and she will induct each new generation into the secrets of the desert elephants, essential for their survival. \n\nThe Huani River Valley is the last real wilderness in Namibia, a life of extremes in the home of the desert elephants.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nat_geo_elephants.render_markdown()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T13:49:58.061315Z",
     "end_time": "2023-04-08T13:49:58.068866Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
